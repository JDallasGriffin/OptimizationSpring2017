---
title: "Stochastic Control & Optimization Project 2"
author: "Anthony Garino, Davis Townsend, Dallas Griffin, Ryan Maas"
date: "February 16, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
setwd("C:/Users/Dallas/OneDrive/MSBA Program/Spring 2017 Courses/Optimization/Homework/Project 2")
```

# Stochastic Control & Optimization Project 2

Below is the code prof provided to do initial data cleaning and created price matrix, shares outstanding matrix, and vector of the tickers
```{r, echo=FALSE}
# read in the data
data = read.csv("N100StkPrices.csv", header = TRUE)

# clean up data
data = na.omit(data)
ticker = data$TICKER

# spun off MDLZ
delete = seq(1, dim(data)[1])[ticker == "MDLZ"]
data = data[-delete, ]

date = apply(as.matrix(data$date), MARGIN = 1, FUN = "toString")
date = as.Date(date, "%Y%m%d")
ticker = data$TICKER
price = data$PRC
shares = data$SHROUT

# Accounting for changes in ticker names

# KFT changed to KRFT in Oct 2012.
ticker[ticker == "KFT"] = "KRFT"

# SXCI changed to CTRX in Jul 2012.
ticker[ticker == "SXCI"] = "CTRX"

# HANS changed to MNST in Jan 2012.
ticker[ticker == "HANS"] = "MNST"

# convert prices to a matrix, arranged by rows of dates and columns of tickers
unique_dates = sort(unique((date)))
unique_tickers = sort(unique(ticker))

priceMat = matrix(NA, length(unique_dates), length(unique_tickers))
sharesMat = matrix(0, length(unique_dates), length(unique_tickers))

for (i in 1:length(unique_tickers)) {
  tic = unique_tickers[i]
  idx = is.element(unique_dates, date[ticker == tic])
  
  priceMat[idx, i] = price[ticker == tic]
  sharesMat[idx, i] = shares[ticker == tic]
}

rownames(priceMat) = as.character(unique_dates)
rownames(sharesMat) = as.character(unique_dates)
colnames(priceMat) = as.character(unique_tickers)
colnames(sharesMat) = as.character(unique_tickers)

rm(list = c("data", "delete", "i", "idx", "price", "shares", "tic", "ticker", "date"))
```
# 1 - Generate daily returns matrix for each stock:
*NOTE: 1.0 means 1% daily stock return*
```{r}
#create empty matrix to populate with the results
returnsMatrix = matrix(nrow=250, ncol=100)

#loop through every row and every column, if not in the first row calculate daily return by the formula:
# ((closing price - prev close price)/prev close price)*100
for(i in 1:nrow(priceMat)) {
  for(j in 1:ncol(priceMat)) {
    if (i>1){
      returnsMatrix[i,j] = ((priceMat[i,j] - priceMat[i-1,j])/priceMat[i-1,j])*100
    }
    
  }
}
rownames(returnsMatrix) = as.character(unique_dates)
colnames(returnsMatrix) = as.character(unique_tickers)
returnsMatrix[2:6,1:5]
```

# 2 - Calculate correlation matrix for daily returns
```{r}
stockCorr = cor(returnsMatrix, y=NULL, use="complete.obs")
```

# 3 - Integer Program for Stock Weights

## Define Function
```{r}
constructFund = function(rho, q, priceMat, sharesMat, unique_tickers, unique_dates){
  
  library(lpSolveAPI)
  
  n = dim(priceMat)[2]
  
  # if there's n = 100 stocks, theres 100*100+100 = 10100 decision variables
  # 10000 x~ij~ values
  # 100 y~j~ values
  # The number of constraints depends on n; there are n^2 + n + 1 constraints
  
  LP=make.lp(0,n^2+n)
  set.objfn(LP, c(as.vector(rho), rep(0,n)))
  lp.control(LP,sense='max')
  set.type(LP, (1:n^2+n), "binary") #forces all variables to be binary
  
  # constraint x~ij~ <= y~j
  for (i in 1:n^2){
    if (i%%n != 0){
      add.constraint(LP,c(rep(0,i-1),1,rep(0,n^2-i),rep(0,i%%n-1),-1,rep(0,n-i%%n)), "<=", 0)
    }else{
      add.constraint(LP,c(rep(0,i-1),1,rep(0,n^2-i),rep(0,n-1),-1), "<=", 0)
    }
  }
  
  # constraint sum(x~ij~) = 1
  for (i in 1:n){
    add.constraint(LP,c(rep(0,(i-1)*n),rep(1,n),rep(0,(n-i)*n),rep(0,100)), "=", 1)
  }
  
  # contraint sum(y~j~) = q
  add.constraint(LP,c(rep(0,n^2), rep(1,n)), "=", q)
  
  # solve linear program
  solve(LP)
  #get.objective(LP)
  solution = get.variables(LP)
  x = solution[1:10000]
  y = tail(solution,100)
  
  x_mat = matrix(x,nrow = 100,ncol = 100, byrow=TRUE)
  
  # gets the share price and number of shares from the last date - 12/31
  marketValue = tail(sharesMat,1)*tail(priceMat,1)
  totalMarket = sum(marketValue)
  
  w = array()
  
  for (i in 1:n){
    w = c(w, sum(x_mat[,i]*marketValue)/totalMarket)
  }
  w = tail(w,100)
  
  return(w)
}
```
## Create End of 2012 Index Portfolio
```{r}
q = 25

weights = constructFund(stockCorr, q, priceMat, sharesMat, unique_tickers, unique_dates)

# Create dataframe of weights v. ticker
weight_df = data.frame(unique_tickers,weights)
names(weight_df) = c('Ticker','Weight')

#Filter out tickets with 0 weight to keep only the q stocks in the index
weight_index_df = weight_df[weight_df$Weight > 0,]
weight_index_df
```
# 4 - 2013 Returns with Index Portfolio

```{r, echo=FALSE}
# read in the data
mdata = read.csv("N100Monthly.csv", header = TRUE, stringsAsFactors = FALSE)

# clean up data
mdate = apply(as.matrix(mdata$date), MARGIN = 1, FUN = "toString")
mdate = as.Date(mdate, "%Y%m%d")

mticker = mdata$TICKER
mprice = mdata$PRC
mshares = mdata$SHROUT
mticker[mticker == "FOXA"] = "NWSA"


unique_mdates = sort(unique((mdate)))
unique_mtickers = sort(unique(mticker))

idx = is.element(unique_mtickers, unique_tickers)

monthlyPriceMat = matrix(NA, length(unique_mdates), length(unique_tickers))

for (i in 1:length(unique_tickers)) {
  tic = unique_tickers[i]
  idx = is.element(unique_mdates, mdate[mticker == tic])
  monthlyPriceMat[idx, i] = mprice[mticker == tic]
}

rownames(monthlyPriceMat) = as.character(unique_mdates)
colnames(monthlyPriceMat) = as.character(unique_tickers)

rm("mdata", "i", "idx", "mprice", "mshares", "mticker", "tic", "mdate")
```

## Calculate Shares Purchased for Index and NASDAQ 100
```{r}
# Get share price and counts from last week of 2012 (12/31)
EoY_MVs = tail(sharesMat,1)*tail(priceMat,1)
EoY_MV_NAS100 = sum(EoY_MVs)
# Calculate MV weight of each stock as % of total NASDAQ 100
NAS100_weights = EoY_MVs / EoY_MV_NAS100

#Total Investment Capital: $1 Mil
capital = 1000000

# Calculate shares purchased on 12/31 for NASDAQ 100 and Index
shares_index = capital * weights / tail(priceMat,1)
shares_nas100 = capital * NAS100_weights / tail(priceMat,1)
```
## Calculate Index Returns
```{r}
# Track value of shares over each month based on stock price
market_value_idx = monthlyPriceMat %*% as.vector(shares_index)
market_value_nas100 = monthlyPriceMat %*% as.vector(shares_nas100)

#Create vectory of total market value of investment for NASDAQ 100 and Index
total_mv_idx = c(capital,rowSums(market_value_idx))
total_mv_nas100 = c(capital,rowSums(market_value_nas100))

unique_mdates2 = c(as.Date('2012-12-31'),unique_mdates)
```
## Compare Performance
```{r}
# Visualize comparative performance of index and overall NASDAQ
plot(x=unique_mdates2,y=total_mv_idx,type = 'l',main = 'Performance of $1M Investment in NASDAQ 100 v. Index',xlab = 'Month',ylab = 'Market Value', col = 'red')
lines(x=unique_mdates2,y=total_mv_nas100, col = 'blue')
legend(as.Date('2013-10-05'),1100000,c('NAS 100','INDEX'),lty=c(1,1),lwd=c(2,2),col=c('blue','red'))

cat('Correlation: ',cor(rowSums(market_value_idx),rowSums(market_value_nas100)))
```

The 25-stock index using correlation between returns as the similarity matrix performs quite well, with a correlation of 97.7%. In the next section, we will try to improve the tracking of the index by trying additional similarity matrices.

# 5 - New Similarity Matrix

## Using Correlation between Market Caps
```{r}
similarityMat = function(priceMat, sharesMat, unique_tickers,unique_dates){
#fill empty matrix with market cap of each stock per day
  emptyMat = matrix(nrow=250, ncol=100)
  for(i in 1:nrow(priceMat)) {
    for(j in 1:ncol(priceMat)){
      emptyMat[i,j] = (priceMat[i,j]*sharesMat[i,j])
    }
  }
  rho = cor(emptyMat, y=NULL, use="complete.obs")
  return(rho)
}

rho = similarityMat(priceMat, sharesMat, unique_tickers,unique_dates)
```

## Get Index Weights
```{r}
weights = constructFund(rho, q, priceMat, sharesMat, unique_tickers, unique_dates)

# Create dataframe of weights v. ticker
weight_df = data.frame(unique_tickers,weights)
names(weight_df) = c('Ticker','Weight')

#Filter out tickets with 0 weight to keep only the q stocks in the index
weight_index_df = weight_df[weight_df$Weight > 0,]
weight_index_df
```

## Portfolio Performance Comparison
```{r}
# Get share price and counts from last week of 2012 (12/31)
EoY_MVs = tail(sharesMat,1)*tail(priceMat,1)
EoY_MV_NAS100 = sum(EoY_MVs)
# Calculate MV weight of each stock as % of total NASDAQ 100
NAS100_weights = EoY_MVs / EoY_MV_NAS100

#Total Investment Capital: $1 Mil
capital = 1000000

# Calculate shares purchased on 12/31 for NASDAQ 100 and Index
shares_index = capital * weights / tail(priceMat,1)
shares_nas100 = capital * NAS100_weights / tail(priceMat,1)

## Calculate Index Returns
# Track value of shares over each month based on stock price
market_value_idx = monthlyPriceMat %*% as.vector(shares_index)
market_value_nas100 = monthlyPriceMat %*% as.vector(shares_nas100)

#Create vectory of total market value of investment for NASDAQ 100 and Index
total_mv_idx = c(capital,rowSums(market_value_idx))
total_mv_nas100 = c(capital,rowSums(market_value_nas100))

unique_mdates2 = c(as.Date('2012-12-31'),unique_mdates)

# Visualize comparative performance of index and overall NASDAQ
plot(x=unique_mdates2,y=total_mv_idx,type = 'l',main = 'Performance of $1M Investment in NASDAQ 100 v. Index',xlab = 'Month',ylab = 'Market Value', col = 'red')
lines(x=unique_mdates2,y=total_mv_nas100, col = 'blue')
legend(as.Date('2013-10-05'),1100000,c('NAS 100','INDEX'),lty=c(1,1),lwd=c(2,2),col=c('blue','red'))

cat('Correlation: ',cor(rowSums(market_value_idx),rowSums(market_value_nas100)))

```
The index of market cap tracks quite closely and consistently outperforms the NAS 100. With a correlation of 99%, this model outperforms the 25-stock index based on the returns correlation (which had a correlation of ~97%).

A possible reason this index outperforms is because changes in market cap takes into account the size of the companies in addition to their returns. Therefore companies with similar returns AND size are grouped together, resulting in a more accurate tracking index.